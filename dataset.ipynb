{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yli927/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 7.94k/7.94k [00:00<00:00, 4.32MB/s]\n",
      "Downloading data: 100%|██████████| 2.31M/2.31M [00:00<00:00, 7.03MB/s]\n",
      "Downloading data: 100%|██████████| 419k/419k [00:00<00:00, 2.41MB/s]\n",
      "Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 302738.53 examples/s]\n",
      "Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 266410.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 7473\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 1319\n",
      "    })\n",
      "})\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "gsm8k = load_dataset(\"gsm8k\", 'main')\n",
    "print(gsm8k)\n",
    "print(gsm8k['train'][0]['question'])\n",
    "print(gsm8k['train'][0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import several open-source LLMs\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf')\n",
    "# model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-hf')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lmsys/vicuna-7b-v1.5\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"lmsys/vicuna-7b-v1.5\").to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try answering the first question\n",
    "input_ids = tokenizer.encode(gsm8k['train'][0]['question'], return_tensors='pt')\n",
    "sample_output = model.generate(input_ids, do_sample=True, top_k=50, max_length=1000, top_p=0.95, num_return_sequences=1)\n",
    "print(\"Response:\", tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "print(\"Answer:\", gsm8k['train'][0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
